# Experimance Agent Service Configuration
# This configuration uses the Pipecat backend for local audio processing

service_name = "agent"

# Agent backend selection - use pipecat for local audio processing
agent_backend = "pipecat"

speech_detection_enabled = true

# Conversation cooldown settings
# After a conversation ends (e.g., saying goodbye), wait this long before starting a new one
conversation_cooldown_duration = 12.0  # seconds

# End cooldown early if audience leaves and returns (allows immediate restart on audience change)
# This prevents the same person from immediately restarting, but allows new people to start immediately
cancel_cooldown_on_absence = true

[backend_config]
prompt_path="projects/fire/fire_spirit_prompt.md"

[backend_config.pipecat]
# Pipeline mode: "realtime" for OpenAI Realtime Beta or "ensemble" for separate STT/LLM/TTS
mode = "realtime"  # Change to "realtime" to use OpenAI Realtime Beta

# Audio settings
audio_in_enabled = true
audio_out_enabled = true
audio_in_sample_rate = 48000
audio_out_sample_rate = 48000

# Audio device selection (comment out to use default devices)
# Use `uv run python scripts/audio_recovery.py list` to list available devices
# Device names support partial matching (e.g., "Yealink" matches "Yealink SP92 Speaker")
# For better performance, you can also specify device indices directly:
audio_input_device_name = "AIRHUG"   # USB Conference microphone
audio_output_device_name = "AIRHUG"  # USB Conference speaker
# Alternatively, use indices for faster startup (uncomment to use):
# audio_input_device_index = 6   # Yealink device index
# audio_output_device_index = 6  # Yealink device index

# Audio error handling
suppress_audio_errors = true         # Suppress ALSA/JACK error messages
audio_device_retry_attempts = 3      # Retry attempts for device initialization
audio_device_retry_delay = 1.0       # Delay between retries (seconds)

# Voice Activity Detection
vad_enabled = true

# LLM settings
openai_model = "gpt-4o"  # For ensemble mode

# OpenAI Realtime settings (realtime mode only)
openai_realtime_model = "gpt-4o-realtime-preview-2025-06-03"
openai_voice = "alloy"  # Options: alloy, echo, fable, onyx, nova, shimmer
turn_detection_threshold = 0.5
turn_detection_silence_ms = 800

# TTS (Text-to-Speech) settings (ensemble mode only)
elevenlabs_voice_id = "EXAVITQu4vr4xnSDxMaL"  # Bella voice
cartesia_voice_id = "bf0a246a-8642-498a-9950-80c35e9276b5"

[vision]
audience_detection_enabled = true
reolink_enabled = true

# Reolink Camera Settings
reolink_host = "192.168.2.229"          # Your camera IP
reolink_user = "admin"                  # Camera username (can override with REOLINK_USER env var)
# reolink_password - NEVER set here! Use REOLINK_PASSWORD environment variable in .env file
reolink_https = true                    # Use HTTPS (recommended)
reolink_channel = 0                     # Camera channel (usually 0)
reolink_hysteresis_count = 3            # Readings needed for state change (stability)
reolink_timeout = 2                     # Timeout for checking for people

# Audience Detection Settings  
audience_detection_interval = 1.0       # Check camera every second
conversation_cooldown_duration = 30     # 30s between conversations
cancel_cooldown_on_absence = true       # Cancel cooldown if audience leaves then returns

[transcript]
# Transcript management
display_transcripts = false
transcript_max_lines = 3
transcript_line_duration = 10.0
transcript_fade_duration = 1.0

# Speaker names
agent_speaker_name = "Experimance"
human_speaker_name = "Visitor"

# Transcript archival
save_transcripts = true

