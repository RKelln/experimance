## Image server configuration

# General settings
cache_dir = "media/images/generated"         # Directory to cache generated images
max_cache_size_gb = 2.0      # Maximum size of image cache in GB

# ZeroMQ configuration
#[zmq]

# Generator configuration
[generator]
strategy = "vastai"     # Options: "falai", "openai", "sdxl", "mock", "vastai"
timeout = 12

# FAL.AI configuration
[fal_comfy]
#endpoint = "comfy/RKelln/experimance_hyper_depth_v5"
endpoint = "comfy/RKelln/experimancexilightningdepth"
model_url = "https://civitai.com/api/download/models/471120?type=Model&format=SafeTensor&size=full&fp=fp16"
lora_url = "https://civitai.com/api/download/models/152309?type=Model&format=SafeTensor"
lora_strength = 1.0
timeout = 120

# VastAI configuration
[vastai]
model_name="lightning"
pre_warm = true           # Pre-warm the generator on startup
create_if_none = true     # Create instance if none exists
wait_for_ready = true     # Wait for instance to be ready
control_guidance_end = 0.8

# Fake image generator
[mock]
#strategy: Literal["mock"] = "mock"
#image_size: tuple = (1024, 1024)
#background_color: tuple = (100, 150, 200)
#text_color: tuple = (255, 255, 255)
use_existing_images = true
existing_images_dir = "media/images/generated"