# Experimance Agent Service Configuration
# This configuration uses the Pipecat backend for local audio processing

service_name = "agent"

# Agent backend selection - use pipecat for local audio processing
agent_backend = "pipecat"

# Tool calling capabilities
tool_calling_enabled = true
biome_suggestions_enabled = true
speech_detection_enabled = true

# Conversation cooldown settings
# After a conversation ends (e.g., saying goodbye), wait this long before starting a new one
conversation_cooldown_duration = 12.0  # seconds

# End cooldown early if audience leaves and returns (allows immediate restart on audience change)
# This prevents the same person from immediately restarting, but allows new people to start immediately
cancel_cooldown_on_absence = true

[backend_config.pipecat]
# Pipecat-specific configuration
system_prompt = "prompt.md"

# Pipeline mode: "realtime" for OpenAI Realtime Beta or "ensemble" for separate STT/LLM/TTS
mode = "ensemble"  # Change to "realtime" to use OpenAI Realtime Beta

# ensemble mode requires a flow file:
flow_file = "flows/experimance_flow.py"

# Audio settings
audio_in_enabled = true
audio_out_enabled = true
audio_in_sample_rate = 16000
audio_out_sample_rate = 16000

# Audio device selection (comment out to use default devices)
# Use `uv run python scripts/audio_recovery.py list` to list available devices
# Device names support partial matching (e.g., "Yealink" matches "Yealink SP92 Speaker")
# For better performance, you can also specify device indices directly:
audio_input_device_name = "Yealink"   # USB Conference microphone
audio_output_device_name = "Yealink"  # USB Conference speaker
# Alternatively, use indices for faster startup (uncomment to use):
# audio_input_device_index = 6   # Yealink device index
# audio_output_device_index = 6  # Yealink device index

# Audio error handling
suppress_audio_errors = true         # Suppress ALSA/JACK error messages
audio_device_retry_attempts = 3      # Retry attempts for device initialization
audio_device_retry_delay = 1.0       # Delay between retries (seconds)

# Voice Activity Detection
vad_enabled = true

# LLM settings
openai_model = "gpt-4o"  # For ensemble mode

# OpenAI Realtime settings (realtime mode only)
openai_realtime_model = "gpt-4o-realtime-preview-2025-06-03"
openai_voice = "alloy"  # Options: alloy, echo, fable, onyx, nova, shimmer
turn_detection_threshold = 0.5
turn_detection_silence_ms = 800

# TTS (Text-to-Speech) settings (ensemble mode only)
elevenlabs_voice_id = "EXAVITQu4vr4xnSDxMaL"  # Bella voice
cartesia_voice_id = "bf0a246a-8642-498a-9950-80c35e9276b5"

[vision]
# Vision processing configuration
webcam_enabled = true
webcam_device_name = "eMeet"
webcam_width = 640
webcam_height = 480
webcam_fps = 30

# Audience detection
audience_detection_enabled = true
audience_detection_interval = 1.0
stable_readings_required = 3

# Vision Language Model
vlm_enabled = false
vlm_model = "moondream"
vlm_analysis_interval = 10.0
vlm_max_image_size = 512
vlm_device = "cpu"  # cuda

[transcript]
# Transcript management
display_transcripts = false
transcript_max_lines = 3
transcript_line_duration = 10.0
transcript_fade_duration = 1.0

# Speaker names
agent_speaker_name = "Experimance"
human_speaker_name = "Visitor"

# Transcript archival
save_transcripts = true
transcript_directory = "logs/transcripts"
