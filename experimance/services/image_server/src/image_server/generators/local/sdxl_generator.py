import asyncio
import logging
from typing import Optional

from PIL import Image

logger = logging.getLogger(__name__)

from image_server.generators.generator import ImageGenerator

class LocalSDXLGenerator(ImageGenerator):
    """Local SDXL image generator implementation.
    
    Uses a local SDXL model for image generation.
    """
    
    def _configure(self, **kwargs):
        """Configure local SDXL generator settings."""
        self.model_path = kwargs.get("model_path", "stabilityai/stable-diffusion-xl-base-1.0")
        self.dimensions = kwargs.get("dimensions", [1024, 1024])
        self.num_inference_steps = kwargs.get("num_inference_steps", 20)
        self.guidance_scale = kwargs.get("guidance_scale", 7.5)
        self.device = kwargs.get("device", "cuda" if self._cuda_available() else "cpu")
        self._pipeline = None
    
    def _cuda_available(self) -> bool:
        """Check if CUDA is available."""
        try:
            import torch
            return torch.cuda.is_available()
        except ImportError:
            return False
    
    async def generate_image(self, prompt: str, depth_map_b64: Optional[str] = None, **kwargs) -> str:
        """Generate an image using local SDXL model."""
        self._validate_prompt(prompt)
        
        # Initialize pipeline if not already done
        if self._pipeline is None:
            await self._initialize_pipeline()
        
        logger.info(f"LocalSDXLGenerator: Generating image locally for prompt: {prompt[:50]}...")
        
        try:
            # Prepare generation parameters
            generation_kwargs = {
                "prompt": prompt,
                "num_inference_steps": self.num_inference_steps,
                "guidance_scale": self.guidance_scale,
                "width": self.dimensions[0],
                "height": self.dimensions[1]
            }
            
            # Add depth map support if available and provided
            if depth_map_b64 and hasattr(self._pipeline, 'depth_map'):
                # Convert base64 to PIL Image
                depth_image = self._decode_depth_map(depth_map_b64)
                generation_kwargs["image"] = depth_image
            
            # Generate image (run in thread to avoid blocking)
            result = await asyncio.to_thread(
                self._pipeline,
                **generation_kwargs
            )
            
            # Save the generated image
            if hasattr(result, 'images') and len(result.images) > 0:
                output_path = self._get_output_path("png")
                result.images[0].save(output_path)
                logger.info(f"LocalSDXLGenerator: Saved image to {output_path}")
                return output_path
            else:
                raise RuntimeError("No images generated by local model")
                
        except Exception as e:
            logger.error(f"LocalSDXLGenerator: Error generating image: {e}")
            raise RuntimeError(f"Local SDXL generation failed: {e}")
    
    async def _initialize_pipeline(self):
        """Initialize the SDXL pipeline."""
        try:
            from diffusers import StableDiffusionXLPipeline
            import torch
        except ImportError:
            raise RuntimeError("diffusers library not installed. Install with: pip install diffusers torch")
        
        logger.info(f"LocalSDXLGenerator: Initializing SDXL pipeline with model: {self.model_path}")
        
        # Load the pipeline (run in thread to avoid blocking)
        self._pipeline = await asyncio.to_thread(
            StableDiffusionXLPipeline.from_pretrained,
            self.model_path,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
            use_safetensors=True,
            variant="fp16" if self.device == "cuda" else None
        )
        
        # Move to device
        self._pipeline = self._pipeline.to(self.device)
        
        # Enable memory efficient attention if available
        if hasattr(self._pipeline, 'enable_attention_slicing'):
            self._pipeline.enable_attention_slicing()
        
        logger.info(f"LocalSDXLGenerator: Pipeline initialized on {self.device}")
    
    def _decode_depth_map(self, depth_map_b64: str) -> Image.Image:
        """Decode base64 depth map to PIL Image."""
        import base64
        from io import BytesIO
        
        # Remove data URL prefix if present
        if depth_map_b64.startswith('data:'):
            depth_map_b64 = depth_map_b64.split(',', 1)[1]
        
        # Decode base64
        image_data = base64.b64decode(depth_map_b64)
        
        # Load as PIL Image
        return Image.open(BytesIO(image_data))